{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efc95ea-d9c7-4da5-9670-e0e150bfb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Transformers\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "\n",
    "# Sklearn Utilities\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1916280f-544e-452b-a300-05d20292c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPREOCESSING AND GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbfe4e4d-a1bd-4cf2-bffb-984704fd7874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "topic_group\n",
      "Anxiety & Stress           402\n",
      "Relationships              361\n",
      "Family & Parenting         281\n",
      "Mental Health Disorders     83\n",
      "Addiction & Abuse           81\n",
      "Behavioral Changes          68\n",
      "Professional & Legal        39\n",
      "Identity & Spirituality     37\n",
      "Violence & Safety           24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('counselchat-data.csv')\n",
    "\n",
    "# Keep necessary columns and drop missing values\n",
    "df = df[['questionText', 'topics']].dropna()\n",
    "\n",
    "# Ensure 'topics' is properly formatted\n",
    "def parse_topics(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        if ',' in x:\n",
    "            return [topic.strip() for topic in x.split(',')]\n",
    "        else:\n",
    "            return [x.strip()]\n",
    "    return []\n",
    "\n",
    "df['topics'] = df['topics'].apply(parse_topics)\n",
    "\n",
    "# Define topic groups\n",
    "topic_groups = {\n",
    "    'Addiction & Abuse': ['Addiction', 'Substance Abuse', 'Self-harm', 'Eating Disorders'],\n",
    "    'Anxiety & Stress': ['Anxiety', 'Stress', 'Sleep Improvement', 'Trauma', 'Self-esteem'],\n",
    "    'Family & Parenting': ['Family Conflict', 'Parenting', 'Children & Adolescents', 'Marriage'],\n",
    "    'Relationships': ['Relationships', 'Intimacy', 'Relationship Dissolution', 'Social Relationships'],\n",
    "    'Mental Health Disorders': ['Depression', \"Alzheimer's\", 'Diagnosis', 'Grief and Loss'],\n",
    "    'Violence & Safety': ['Domestic Violence', 'Anger Management', 'Military Issues'],\n",
    "    'Professional & Legal': ['Career Counseling', 'Workplace Relationships', 'Legal & Regulatory', 'Professional Ethics'],\n",
    "    'Identity & Spirituality': ['Human Sexuality', 'LGBTQ', 'Spirituality'],\n",
    "    'Behavioral Changes': ['Behavioral Change', 'Counseling Fundamentals']\n",
    "}\n",
    "\n",
    "# Map topics to groups\n",
    "def map_to_group(topics):\n",
    "    for group, keywords in topic_groups.items():\n",
    "        if any(topic in keywords for topic in topics):\n",
    "            return group\n",
    "    return 'Other'\n",
    "\n",
    "df['topic_group'] = df['topics'].apply(map_to_group)\n",
    "\n",
    "# Encode topic groups\n",
    "le = LabelEncoder()\n",
    "df['topic_group_encoded'] = le.fit_transform(df['topic_group'])\n",
    "\n",
    "# Display class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(df['topic_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d6811c-4310-407a-a93e-3fb52e6e8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f9a01e-65eb-4dda-9d61-2b1a7cc42b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Define Dataset class\n",
    "class CounselChatDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(list(texts), padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Create dataset\n",
    "dataset = CounselChatDataset(df['questionText'], df['topic_group_encoded'], tokenizer)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7d869e-a55e-447f-ac5c-8da94349597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c048f96-b076-49ce-bc81-33c3cc9fbe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\pramo\\AppData\\Local\\Temp\\ipykernel_3356\\3109453125.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(le.classes_))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
    "total_steps = len(train_loader) * 3  \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Mixed Precision Training (AMP)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fba30c2-344d-4d54-8c58-0ad0c70a3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with GPU & Mixed Precision  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddb2b3d-8da8-4b26-ba76-0309038b6c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/69 [00:00<?, ?it/s]C:\\Users\\pramo\\AppData\\Local\\Temp\\ipykernel_3356\\3314384827.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:24<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:23<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.6808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:24<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:24<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:26<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:25<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:23<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:23<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:23<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:23<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 10\n",
    "gradient_accumulation_steps = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_loader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / gradient_accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3de8217-b1ae-4df1-bb37-b8a33940b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc65d13f-5314-4873-b310-4f46ca5606f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:04<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8080\n",
      "âœ… Model Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Validation Loop\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        \n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "torch.save(model.state_dict(), 'roberta_gpu_classifier.pth')\n",
    "print(\"âœ… Model Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b9fdc5-9c31-46d2-8429-24160d068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with New Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49fbb46-bf87-4ef9-b18e-957e28890a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\pramo\\AppData\\Local\\Temp\\ipykernel_3356\\921934564.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('roberta_gpu_classifier.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Input: I feel anxious all the time, and I don't know how to cope.\n",
      "ðŸ”® Predicted Topic: Anxiety & Stress\n",
      "\n",
      "ðŸ“ Input: My partner and I are having relationship problems.\n",
      "ðŸ”® Predicted Topic: Relationships\n",
      "\n",
      "ðŸ“ Input: I am struggling with substance abuse and need help quitting.\n",
      "ðŸ”® Predicted Topic: Addiction & Abuse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Model for Inference\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(le.classes_))\n",
    "model.load_state_dict(torch.load('roberta_gpu_classifier.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prediction Function\n",
    "def predict_topic(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return le.inverse_transform([predicted_class])[0]\n",
    "\n",
    "# Test Predictions\n",
    "test_texts = [\n",
    "    \"I feel anxious all the time, and I don't know how to cope.\",\n",
    "    \"My partner and I are having relationship problems.\",\n",
    "    \"I am struggling with substance abuse and need help quitting.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"ðŸ“ Input: {text}\\nðŸ”® Predicted Topic: {predict_topic(text)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ad399f-b2ab-45b1-8019-5e91de904c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\pramo\\AppData\\Local\\Temp\\ipykernel_3356\\1006549268.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('roberta_gpu_classifier.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Input: I want to quit smoking but can't seem to stop.\n",
      "ðŸ”® Predicted Topic: Addiction & Abuse\n",
      "\n",
      "ðŸ“ Input: My self-esteem is so low that I avoid social situations.\n",
      "ðŸ”® Predicted Topic: Anxiety & Stress\n",
      "\n",
      "ðŸ“ Input: I feel hopeless and have no motivation to get out of bed.\n",
      "ðŸ”® Predicted Topic: Mental Health Disorders\n",
      "\n",
      "ðŸ“ Input: My sibling and I are always in conflict, and it's exhausting.\n",
      "ðŸ”® Predicted Topic: Family & Parenting\n",
      "\n",
      "ðŸ“ Input: I'm struggling to come to terms with my sexual orientation.\n",
      "ðŸ”® Predicted Topic: Identity & Spirituality\n",
      "\n",
      "ðŸ“ Input: I feel disconnected from my faith and purpose.\n",
      "ðŸ”® Predicted Topic: Anxiety & Stress\n",
      "\n",
      "ðŸ“ Input: I'm experiencing burnout from my high-pressure job.\n",
      "ðŸ”® Predicted Topic: Anxiety & Stress\n",
      "\n",
      "ðŸ“ Input: My workplace has become toxic, and I can't handle it anymore.\n",
      "ðŸ”® Predicted Topic: Anxiety & Stress\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Model for Inference\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(le.classes_))\n",
    "model.load_state_dict(torch.load('roberta_gpu_classifier.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prediction Function\n",
    "def predict_topic(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return le.inverse_transform([predicted_class])[0]\n",
    "\n",
    "# Test Predictions\n",
    "test_texts = [\n",
    "        \"I want to quit smoking but can't seem to stop.\",\n",
    "        \"My self-esteem is so low that I avoid social situations.\",\n",
    "        \"I feel hopeless and have no motivation to get out of bed.\",\n",
    "         \"My sibling and I are always in conflict, and it's exhausting.\",\n",
    "        \"I'm struggling to come to terms with my sexual orientation.\",\n",
    "        \"I feel disconnected from my faith and purpose.\",\n",
    "    \"I'm experiencing burnout from my high-pressure job.\",\n",
    "    \"My workplace has become toxic, and I can't handle it anymore.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"ðŸ“ Input: {text}\\nðŸ”® Predicted Topic: {predict_topic(text)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e203b820-3029-4d2a-9c4d-4bd868d5b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model, Tokenizer, and LabelEncoder saved successfully in 'rag_model_checkpoint.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Save Model, Tokenizer, and LabelEncoder Together\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),  # Model weights\n",
    "    'tokenizer': tokenizer,                 # Tokenizer\n",
    "    'label_encoder': le                     # Label Encoder\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'rag_model_checkpoint.pth')\n",
    "print(\"âœ… Model, Tokenizer, and LabelEncoder saved successfully in 'rag_model_checkpoint.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb01486-ed5f-48b1-9016-be6fcb3b6865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
